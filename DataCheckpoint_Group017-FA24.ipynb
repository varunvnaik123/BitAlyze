{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "\n",
    "- Parv Chordiya\n",
    "- Vivek Rane\n",
    "- Sonakshi Mohanty\n",
    "- Rahul Bulsara\n",
    "- Varun Naik\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we identify a measurable correlation between specific social media sentiment indicators (such as counts of positive, neutral, and negative posts) on platforms like X (formerly Twitter) and Reddit, and key Bitcoin price metrics? Specifically, we aim to analyze whether changes in sentiment on these platforms are associated with variations in Bitcoin’s price volatility, daily closing price, and trading volume over defined time frames (e.g., hourly, daily, weekly).\n",
    "\n",
    "In this project, sentiment will be measured by categorizing posts as positive, neutral, or negative based on commonly used sentiment indicators. We will then examine how these sentiment trends align with Bitcoin's price action and trading activity, using statistical analysis to determine any significant correlations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In recent years, social media has changed the way information spreads, and it’s even had a big impact on financial markets. This is especially true for the cryptocurrency market and Bitcoin in particular. Because Bitcoin is decentralized and its price is highly volatile, it’s more sensitive to public opinion and speculation. Platforms like Twitter and Reddit have become central spaces where people express their views about Bitcoin, often influencing its price. A famous example of this is how Elon Musk’s tweets can send Bitcoin prices soaring or dropping, showing just how much social media sentiment can drive market behavior[^1](\"#1\").\n",
    "\n",
    "Previous studies have looked into this connection between social media sentiment and Bitcoin prices, and they’ve uncovered some interesting patterns. One notable study used Twitter data to gauge “public mood” and see how it affects Bitcoin price volatility. They found that major price shifts often happened in response to swings in public sentiment on Twitter. By analyzing the positive and negative tones of tweets, this study showed a significant link between these sentiments and Bitcoin’s price changes, particularly when the market was very volatile[^2](\"#2\"). Another study looked at Reddit’s cryptocurrency discussions, analyzing how the amount and sentiment of posts impacted Bitcoin prices. They observed that sudden increases in positive or negative discussions were often followed by price changes, suggesting that social media sentiment can lead to short-term trading behavior that affects prices[^3](\"#3\").\n",
    "\n",
    "While a lot of research has been done on Bitcoin’s price volatility and market trends, combining social media sentiment analysis with Bitcoin price prediction is still a developing area. This project aims to build on what we know by using sentiment analysis to measure the real-time impact of Twitter and Reddit on Bitcoin prices, hoping to see if we can make accurate price predictions based on sentiment trends. By mixing sentiment analysis with time series modeling, this project seeks to deepen our understanding of the relationship between social media and cryptocurrency markets, adding to ongoing research on how online platforms influence financial markets.\n",
    "\n",
    "\n",
    "<a name=\"#1\"></a> Rani Molla(2021, June 14). When Elon Musk tweets, crypto prices move.https://www.vox.com/recode/2021/5/18/22441831/elon-musk-bitcoin-dogecoin-crypto-prices-tesla. \n",
    "\n",
    "<a name=\"#2\"></a> Abraham, J., Higdon, D., Nelson, J., & Ibarra, J. (2018). \"Cryptocurrency price prediction using tweet volumes and sentiment analysis.https://api.semanticscholar.org/CorpusID:52950647\n",
    "\n",
    "<a name=\"#3\"></a>Oliveira, N., Cortez, P., & Areal, N. (2017). The impact of microblogging data for stock market prediction: Using Twitter to predict returns, volatility, trading volume and survey sentiment indices. Expert Syst. Appl., 73, 125-144.https://doi.org/10.1016/j.im.2017.10.004. ^\n",
    "https://api.semanticscholar.org/CorpusID:21682466\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that there is a positive correlation between social media sentiment toward Bitcoin and Bitcoin's price metrics. Specifically:\n",
    "\n",
    "Positive Sentiment Hypothesis: Increases in the proportion of positive mentions of Bitcoin on social media platforms like X (formerly Twitter) and Reddit (categorized based on words or phrases associated with optimism, such as \"bullish,\" \"gains,\" or \"buy\") will be associated with an increase in Bitcoin's closing price, trading volume, or price volatility.\n",
    "\n",
    "Negative Sentiment Hypothesis: Conversely, increases in the proportion of negative mentions (identified by terms reflecting pessimism, such as \"bearish,\" \"losses,\" or \"sell\") will correlate with a decrease in these metrics.\n",
    "\n",
    "For clarity, sentiment will be categorized into positive, neutral, or negative based on keyword counts and sentiment scoring rules that classify posts according to commonly accepted standards. We expect that shifts in sentiment will show a measurable impact on Bitcoin’s price metrics, reflecting the influence of public opinion on market trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "Bitcoin Historical Data\n",
    "\n",
    "- [Link to the dataset](https://www.kaggle.com/datasets/mczielinski/bitcoin-historical-data/data?select=btcusd_1-min_data.csv)\n",
    "- Number of observations: ~ 6,712,281\n",
    "- Number of variables: 6\n",
    "\n",
    "Bitcoin Tweets\n",
    "\n",
    "- [Link to the dataset](https://www.kaggle.com/datasets/kaushiksuresh147/bitcoin-tweets)\n",
    "- Number of observations: ~ 4,689,354\n",
    "- Number of variables: 13\n",
    "\n",
    "Bitcoin Historical Data: This dataset includes historical bitcoin market data at 1-min intervals for select bitcoin exchanges where trading takes place. The important variables in this dataset are # Open which tells us the opening price of Bitcoin for the day and # Close which tells us the value of Bitcoin at the end of that day. # Volume is also insightful as it tells us the volume of Bitcoin transacted during that day. This dataset is quite extensive as it started in 2012. We will most likely clean it by only keeping observations from 2021 to the present as this timeframe is included in our Bitcoin Tweets dataset.\n",
    "\n",
    "Bitcoin Tweets: This dataset contains tweets from Twitter/X that contain the #Bitcoin and #Btc hashtags. This collection started on 6/2/2021 and is updated daily. An important variable in this dataset are date which tells us the UTC time and date when the tweet was posted. We’ll be able to see the price of Bitcoin at the time of these tweets by combining this dataset with the Bitcoin Historical Data. Another important variable is text which gives us the actual content of the tweets. We’ll use sentiment scoring rules to classify tweets as being either negative or positive. More information about our sentiment analysis is included in our hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitcoin Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df = pd.read_csv(\"/Users/rahulbulsara/Downloads/btcusd_1-min_data.csv\")\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitcoin Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert index into `datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df['Timestamp'] = pd.to_datetime(btc_df['Timestamp'], unit='s', utc=True)\n",
    "btc_df.set_index('Timestamp', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for and drop any columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = btc_df.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample data to hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_hourly = btc_df.resample('h').agg({\n",
    "    'Open': 'first',\n",
    "    'High': 'max',\n",
    "    'Low': 'min',\n",
    "    'Close': 'last',\n",
    "    'Volume': 'sum'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitcoin Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"C:/Users/User/Documents/cogs108_data/Bitcoin_tweets.csv\", usecols=['user_followers', 'date', 'text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitcoin tweets Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set index to `datetime` and drop any tweets that don't have valid dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweet_datetime'] = pd.to_datetime(tweets_df['date'], utc=True, errors='coerce')\n",
    "tweets_df.dropna(subset=['tweet_datetime'], inplace=True)\n",
    "\n",
    "tweets_df.set_index('tweet_datetime', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the tweets getting rid of any URLs, emojis and special characters, punctuation, numbers, and whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet_text(text):\n",
    "    text = str(text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    # Remove mentions and hashtags\n",
    "    #text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    # Remove emojis and special characters\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['cleaned_text'] = tweets_df['text'].apply(clean_tweet_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure no tweets are empty after cleaning, and only store those that are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets_df[tweets_df['cleaned_text'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the SentimentIntensityAnalyzer to get the polarity scores for each cleaned tweet in our dataset.\n",
    "\n",
    "Polarity in sentiment analysis refers to the degree of positivity, negativity, or neutrality expressed in a piece of text. It quantifies sentiment on a scale, typically ranging from -1 (strongly negative) to +1 (strongly positive), with 0 representing a neutral sentiment. it is crucial in understanding the emotional tone of social media posts, reviews, or any textual content.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    return sia.polarity_scores(text)['compound']\n",
    "\n",
    "tweets_df['sentiment_score'] = tweets_df['cleaned_text'].apply(get_sentiment_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then categorize each polarity score as positive, neutral, or negative. Since neutral tweets will be 0 or very close to 0, a very small range is used for encoding them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return 'positive'\n",
    "    elif score < -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "tweets_df['sentiment_category'] = tweets_df['sentiment_score'].apply(categorize_sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by hour, just like our bitcoin data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = tweets_df.groupby([pd.Grouper(freq='h'), 'sentiment_category']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure each category exists for each hour of data and fill in with 0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in ['positive', 'neutral', 'negative']:\n",
    "    if category not in sentiment_counts.columns:\n",
    "        sentiment_counts[category] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute features, `total_tweets`, `net_sentiment_score` and `average_sentiment`. \n",
    "\n",
    "`net_sentiment_score` is simply the net amount of directional(positive or negative) tweets divided by total number of tweets.\n",
    "\n",
    "`average_sentiment` is the mean uncategorized sentiment score across each hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts['total_tweets'] = sentiment_counts.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts['net_sentiment_score'] = (sentiment_counts['positive'] - sentiment_counts['negative']) / sentiment_counts['total_tweets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sentiment = tweets_df.resample('h')['sentiment_score'].mean()\n",
    "sentiment_counts['average_sentiment'] = average_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data is missing certain days, we need to filter our bitcoin data to only include days which we have tweets for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_hours = sentiment_counts.index.unique()\n",
    "btc_filtered = btc_hourly.loc[btc_hourly.index.isin(available_hours)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now merge both of our fully proceessed datasets into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = sentiment_counts.reindex(btc_filtered.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = btc_filtered.join(sentiment_counts, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>total_tweets</th>\n",
       "      <th>net_sentiment_score</th>\n",
       "      <th>average_sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-05 10:00:00+00:00</th>\n",
       "      <td>37302.24</td>\n",
       "      <td>37391.12</td>\n",
       "      <td>37049.34</td>\n",
       "      <td>37094.46</td>\n",
       "      <td>97.855257</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.274245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 11:00:00+00:00</th>\n",
       "      <td>37094.46</td>\n",
       "      <td>37700.43</td>\n",
       "      <td>37060.00</td>\n",
       "      <td>37431.08</td>\n",
       "      <td>227.234701</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>31</td>\n",
       "      <td>88</td>\n",
       "      <td>0.238636</td>\n",
       "      <td>0.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 12:00:00+00:00</th>\n",
       "      <td>37430.83</td>\n",
       "      <td>37777.78</td>\n",
       "      <td>37430.83</td>\n",
       "      <td>37706.73</td>\n",
       "      <td>152.645297</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>139</td>\n",
       "      <td>0.402878</td>\n",
       "      <td>0.192934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 13:00:00+00:00</th>\n",
       "      <td>37714.98</td>\n",
       "      <td>37836.97</td>\n",
       "      <td>37462.33</td>\n",
       "      <td>37771.16</td>\n",
       "      <td>255.330184</td>\n",
       "      <td>15</td>\n",
       "      <td>68</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>0.251908</td>\n",
       "      <td>0.130253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 14:00:00+00:00</th>\n",
       "      <td>37766.09</td>\n",
       "      <td>37817.53</td>\n",
       "      <td>37250.00</td>\n",
       "      <td>37301.38</td>\n",
       "      <td>189.317303</td>\n",
       "      <td>15</td>\n",
       "      <td>82</td>\n",
       "      <td>63</td>\n",
       "      <td>160</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.135852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09 19:00:00+00:00</th>\n",
       "      <td>17225.00</td>\n",
       "      <td>17268.00</td>\n",
       "      <td>17211.00</td>\n",
       "      <td>17263.00</td>\n",
       "      <td>33.898095</td>\n",
       "      <td>251</td>\n",
       "      <td>680</td>\n",
       "      <td>615</td>\n",
       "      <td>1546</td>\n",
       "      <td>0.235446</td>\n",
       "      <td>0.125101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09 20:00:00+00:00</th>\n",
       "      <td>17263.00</td>\n",
       "      <td>17328.00</td>\n",
       "      <td>17230.00</td>\n",
       "      <td>17271.00</td>\n",
       "      <td>128.415261</td>\n",
       "      <td>248</td>\n",
       "      <td>705</td>\n",
       "      <td>630</td>\n",
       "      <td>1583</td>\n",
       "      <td>0.241314</td>\n",
       "      <td>0.128724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09 21:00:00+00:00</th>\n",
       "      <td>17270.00</td>\n",
       "      <td>17355.00</td>\n",
       "      <td>17270.00</td>\n",
       "      <td>17325.00</td>\n",
       "      <td>150.895088</td>\n",
       "      <td>214</td>\n",
       "      <td>518</td>\n",
       "      <td>591</td>\n",
       "      <td>1323</td>\n",
       "      <td>0.284958</td>\n",
       "      <td>0.150869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09 22:00:00+00:00</th>\n",
       "      <td>17333.00</td>\n",
       "      <td>17373.00</td>\n",
       "      <td>17321.00</td>\n",
       "      <td>17359.00</td>\n",
       "      <td>50.276312</td>\n",
       "      <td>234</td>\n",
       "      <td>495</td>\n",
       "      <td>465</td>\n",
       "      <td>1194</td>\n",
       "      <td>0.193467</td>\n",
       "      <td>0.116634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09 23:00:00+00:00</th>\n",
       "      <td>17359.00</td>\n",
       "      <td>17393.00</td>\n",
       "      <td>17329.00</td>\n",
       "      <td>17350.00</td>\n",
       "      <td>113.708079</td>\n",
       "      <td>196</td>\n",
       "      <td>444</td>\n",
       "      <td>434</td>\n",
       "      <td>1074</td>\n",
       "      <td>0.221601</td>\n",
       "      <td>0.119803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Open      High       Low     Close      Volume  \\\n",
       "Timestamp                                                                       \n",
       "2021-02-05 10:00:00+00:00  37302.24  37391.12  37049.34  37094.46   97.855257   \n",
       "2021-02-05 11:00:00+00:00  37094.46  37700.43  37060.00  37431.08  227.234701   \n",
       "2021-02-05 12:00:00+00:00  37430.83  37777.78  37430.83  37706.73  152.645297   \n",
       "2021-02-05 13:00:00+00:00  37714.98  37836.97  37462.33  37771.16  255.330184   \n",
       "2021-02-05 14:00:00+00:00  37766.09  37817.53  37250.00  37301.38  189.317303   \n",
       "...                             ...       ...       ...       ...         ...   \n",
       "2023-01-09 19:00:00+00:00  17225.00  17268.00  17211.00  17263.00   33.898095   \n",
       "2023-01-09 20:00:00+00:00  17263.00  17328.00  17230.00  17271.00  128.415261   \n",
       "2023-01-09 21:00:00+00:00  17270.00  17355.00  17270.00  17325.00  150.895088   \n",
       "2023-01-09 22:00:00+00:00  17333.00  17373.00  17321.00  17359.00   50.276312   \n",
       "2023-01-09 23:00:00+00:00  17359.00  17393.00  17329.00  17350.00  113.708079   \n",
       "\n",
       "                           negative  neutral  positive  total_tweets  \\\n",
       "Timestamp                                                              \n",
       "2021-02-05 10:00:00+00:00         0        5         6            11   \n",
       "2021-02-05 11:00:00+00:00        10       47        31            88   \n",
       "2021-02-05 12:00:00+00:00        12       59        68           139   \n",
       "2021-02-05 13:00:00+00:00        15       68        48           131   \n",
       "2021-02-05 14:00:00+00:00        15       82        63           160   \n",
       "...                             ...      ...       ...           ...   \n",
       "2023-01-09 19:00:00+00:00       251      680       615          1546   \n",
       "2023-01-09 20:00:00+00:00       248      705       630          1583   \n",
       "2023-01-09 21:00:00+00:00       214      518       591          1323   \n",
       "2023-01-09 22:00:00+00:00       234      495       465          1194   \n",
       "2023-01-09 23:00:00+00:00       196      444       434          1074   \n",
       "\n",
       "                           net_sentiment_score  average_sentiment  \n",
       "Timestamp                                                          \n",
       "2021-02-05 10:00:00+00:00             0.545455           0.274245  \n",
       "2021-02-05 11:00:00+00:00             0.238636           0.109375  \n",
       "2021-02-05 12:00:00+00:00             0.402878           0.192934  \n",
       "2021-02-05 13:00:00+00:00             0.251908           0.130253  \n",
       "2021-02-05 14:00:00+00:00             0.300000           0.135852  \n",
       "...                                        ...                ...  \n",
       "2023-01-09 19:00:00+00:00             0.235446           0.125101  \n",
       "2023-01-09 20:00:00+00:00             0.241314           0.128724  \n",
       "2023-01-09 21:00:00+00:00             0.284958           0.150869  \n",
       "2023-01-09 22:00:00+00:00             0.193467           0.116634  \n",
       "2023-01-09 23:00:00+00:00             0.221601           0.119803  \n",
       "\n",
       "[4039 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df = pd.read_csv(r'C:\\Users\\User\\Group017-FA24\\Group017-FA24\\Data\\mergedData.csv', index_col=0)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data science project, we prioritize ethics and privacy by using only open-source datasets that adhere to strict data usage policies, ensuring we respect data ownership and compliance with privacy regulations. \n",
    "\n",
    "Bitcoin data is publicly available and doesn’t raise any violations on privacy and ethics. Analyzing social media sentiment does raise some flags on the use of peoples opinions and posts to represent and train our sentiment model but all scraped data will come from public posts.\n",
    "\n",
    "Conducting sentiment analysis on social media platforms inherently carries risks of bias. Different sentiment tones can arise due to cultural, linguistic, and regional aspects. Additionally, sentiment extraction methods may amplify certain viewpoints or under-represent others, leading to biased outcomes in our analysis. For instance, words or phrases with different meanings across regions can cause sentiment scores to differ and be inaccurate.\n",
    "\n",
    "To mitigate these biases, we employ normalization techniques and careful preprocessing steps to ensure that our sentiment model is as objective as possible. This includes standardizing language differences, removing outliers, and applying region-specific sentiment adjustments when feasible. Furthermore, we plan to perform a bias audit on our model’s outputs to identify and address any unintended skew in our results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- We will use iMessage to communicate. We will meet at least once a week. If a group member has a question and they put it in the groupchat, they should be able to get their question answered within one hour\n",
    "- Everyone is expected to contribute to the group tasks each week. Tasks will be delegated based on preference and everyone should have around an equal amount of work. \n",
    "- If someone is struggling with their work or unable to complete something, they should tell the rest of the group ASAP \n",
    "- Be blunt but polite if you want to express a disagreement or different opinion. It is important to have effective communication and be direct. \n",
    "- It is important to take everyone’s perspective into consideration and hear each other out during times of conflict. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your team's specific project timeline. An example timeline has been provided. Changes the dates, times, names, and details to fit your group's plan.\n",
    "\n",
    "If you think you will need any special resources or training outside what we have covered in COGS 108 to solve your problem, then your proposal should state these clearly. For example, if you have selected a problem that involves implementing multiple neural networks, please state this so we can make sure you know what you’re doing and so we can point you to resources you will need to implement your project. Note that you are not required to use outside methods.\n",
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 10/30  |  1 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 10/30  |  10 AM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 10/30  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 11/18  | 6 PM  | Import & Wrangle Data; EDA | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 11/23  | 12 PM  | Finalize wrangling/EDA; Begin Analysis | Discuss/edit Analysis; Complete project check-in |\n",
    "| 12/10  | 12 PM  | Complete analysis; Draft results/conclusion/discussion| Discuss/edit full project |\n",
    "| 12/11  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
